{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动并行计算\n",
    "\n",
    "MXNet 后端会自动构建计算图。通过计算图，系统可以知道所有计算的依赖关系，并可以选择将没有依赖关系的多个任务并行执行来获得计算性能的提升。例如[“异步计算”](async-computation.md)一节的第一个例子里依次执行了`a = nd.ones((1, 2))`和`b = nd.ones((1, 2))`。这两步计算之间并没有依赖关系，因此系统可以选择并行执行它们。\n",
    "\n",
    "通常，一个运算符会用到所有 CPU 或单个 GPU 上全部的计算资源。例如，`dot`操作符会用到所有 CPU（即使是一台机器上有多个 CPU 处理器）或单个 GPU 上所有的线程。如果每个操作符的计算量足够大，只在 CPU 上或者单个 GPU 上并行运行多个运算符时，每个运算符的运行只分到 CPU 或单个 GPU 上部分计算资源。即使这些计算可以并行，最终计算性能的提升可能并不明显。本节中探讨的自动并行计算主要关注同时使用 CPU 和 GPU 的并行计算，以及计算和通讯的并行。\n",
    "\n",
    "首先导入本节中实验所需的包或模块。注意，我们需要至少一个 GPU 才能运行本节实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gluonbook as gb\n",
    "import mxnet as mx\n",
    "from mxnet import nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU 和 GPU 的并行计算\n",
    "\n",
    "我们先介绍 CPU 和 GPU 的并行计算，例如程序中的计算既发生在 CPU 上，又发生在 GPU 上。先定义`run`函数，令它做 10 次矩阵乘法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(x):\n",
    "    return [nd.dot(x, x) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，分别在 CPU 和 GPU 上创建 NDArray。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[18:33:45] src/resource.cc:153: GPU is not enabled\n\nStack trace returned 10 entries:\n[bt] (0) 0   libmxnet.so                         0x000000011468e3b4 libmxnet.so + 21428\n[bt] (1) 1   libmxnet.so                         0x000000011468e16f libmxnet.so + 20847\n[bt] (2) 2   libmxnet.so                         0x000000011468dde9 libmxnet.so + 19945\n[bt] (3) 3   libmxnet.so                         0x0000000115c192b2 MXTVMBridge + 3528914\n[bt] (4) 4   libmxnet.so                         0x0000000115794727 MXNDListFree + 411335\n[bt] (5) 5   libmxnet.so                         0x0000000115793c27 MXNDListFree + 408519\n[bt] (6) 6   libmxnet.so                         0x00000001157983ae MXNDListFree + 426830\n[bt] (7) 7   libmxnet.so                         0x000000011570968a MXCustomFunctionRecord + 20250\n[bt] (8) 8   libmxnet.so                         0x000000011570a890 MXImperativeInvokeEx + 176\n[bt] (9) 9   libffi.6.dylib                      0x0000000107529884 ffi_call_unix64 + 76\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0087cbb550c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda2/envs/gluon/lib/python3.6/site-packages/mxnet/ndarray/random.py\u001b[0m in \u001b[0;36muniform\u001b[0;34m(low, high, shape, dtype, ctx, out, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \"\"\"\n\u001b[1;32m    100\u001b[0m     return _random_helper(_internal._random_uniform, _internal._sample_uniform,\n\u001b[0;32m--> 101\u001b[0;31m                           [low, high], shape, dtype, ctx, out, kwargs)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/gluon/lib/python3.6/site-packages/mxnet/ndarray/random.py\u001b[0m in \u001b[0;36m_random_helper\u001b[0;34m(random, sampler, params, shape, dtype, ctx, out, kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;34m\"Distribution parameters must all have the same type, but got \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;34m\"both %s and %s.\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     raise ValueError(\"Distribution parameters must be either NDArray or numbers, \"\n",
      "\u001b[0;32m~/miniconda2/envs/gluon/lib/python3.6/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36m_random_uniform\u001b[0;34m(low, high, shape, ctx, dtype, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/gluon/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         ctypes.byref(out_stypes)))\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/gluon/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \"\"\"\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [18:33:45] src/resource.cc:153: GPU is not enabled\n\nStack trace returned 10 entries:\n[bt] (0) 0   libmxnet.so                         0x000000011468e3b4 libmxnet.so + 21428\n[bt] (1) 1   libmxnet.so                         0x000000011468e16f libmxnet.so + 20847\n[bt] (2) 2   libmxnet.so                         0x000000011468dde9 libmxnet.so + 19945\n[bt] (3) 3   libmxnet.so                         0x0000000115c192b2 MXTVMBridge + 3528914\n[bt] (4) 4   libmxnet.so                         0x0000000115794727 MXNDListFree + 411335\n[bt] (5) 5   libmxnet.so                         0x0000000115793c27 MXNDListFree + 408519\n[bt] (6) 6   libmxnet.so                         0x00000001157983ae MXNDListFree + 426830\n[bt] (7) 7   libmxnet.so                         0x000000011570968a MXCustomFunctionRecord + 20250\n[bt] (8) 8   libmxnet.so                         0x000000011570a890 MXImperativeInvokeEx + 176\n[bt] (9) 9   libffi.6.dylib                      0x0000000107529884 ffi_call_unix64 + 76\n\n"
     ]
    }
   ],
   "source": [
    "x_cpu = nd.random.uniform(shape=(2000, 2000))\n",
    "x_gpu = nd.random.uniform(shape=(6000, 6000), ctx=mx.gpu(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，分别使用它们在 CPU 和 GPU 上运行`run`函数并打印所需时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on CPU. time: 1.2819 sec\n",
      "Then run on GPU. time: 0.3083 sec\n"
     ]
    }
   ],
   "source": [
    "run(x_cpu)  # 预热开始。\n",
    "run(x_gpu)\n",
    "nd.waitall()  # 预热结束。\n",
    "\n",
    "with gb.Benchmark('Run on CPU.'):\n",
    "    run(x_cpu)\n",
    "    nd.waitall()\n",
    "\n",
    "with gb.Benchmark('Then run on GPU.'):\n",
    "    run(x_gpu)\n",
    "    nd.waitall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们去掉`run(x_cpu)`和`run(x_gpu)`两个计算任务之间的`nd.waitall()`，希望系统能自动并行这两个任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on both CPU and GPU in parallel. time: 1.3653 sec\n"
     ]
    }
   ],
   "source": [
    "with gb.Benchmark('Run on both CPU and GPU in parallel.'):\n",
    "    run(x_cpu)\n",
    "    run(x_gpu)\n",
    "    nd.waitall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，当两个计算任务一起执行时，执行总时间小于它们分开执行的总和。这表示，MXNet 能有效地在 CPU 和 GPU 上自动并行计算。\n",
    "\n",
    "\n",
    "## 计算和通讯的并行计算\n",
    "\n",
    "在同时使用 CPU 和 GPU 的计算中，我们经常需要在 CPU 和 GPU 之间复制数据，造成数据的通讯。在下面例子中，我们在 GPU 上计算，然后将结果复制回 CPU。我们分别打印 GPU 上计算时间和 GPU 到 CPU 的通讯时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on GPU. time: 0.3244 sec\n",
      "Then copy to CPU. time: 0.6433 sec\n"
     ]
    }
   ],
   "source": [
    "def copy_to_cpu(x):\n",
    "    return [y.copyto(mx.cpu()) for y in x]\n",
    "\n",
    "with gb.Benchmark('Run on GPU.'):\n",
    "    y = run(x_gpu)\n",
    "    nd.waitall()\n",
    "\n",
    "with gb.Benchmark('Then copy to CPU.'):\n",
    "    copy_to_cpu(y)\n",
    "    nd.waitall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们去掉计算和通讯之间的`waitall`函数，打印这两个任务完成的总时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run and copy in parallel. time: 0.6471 sec\n"
     ]
    }
   ],
   "source": [
    "with gb.Benchmark('Run and copy in parallel.'):\n",
    "    y = run(x_gpu)\n",
    "    copy_to_cpu(y)\n",
    "    nd.waitall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，执行计算和通讯的总时间小于两者分别执行的耗时之和。需要注意的是，这个计算并通讯的任务不同于本节之前介绍的同时使用 CPU 和 GPU 并行计算的任务。这里的运行和通讯之间有依赖关系：`y[i]`必须先计算好才能复制到 CPU。所幸的是，在计算`y[i]`的时候系统可以复制`y[i-1]`，从而减少计算和通讯的总运行时间。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* MXNet 能够通过自动并行计算提升计算性能，例如 CPU 和 GPU 的并行计算以及计算和通讯的并行。\n",
    "\n",
    "\n",
    "## 练习\n",
    "\n",
    "* 本节中定义的`run`函数里做了 10 次运算。它们之间也没有依赖关系。设计实验，看看 MXNet 有没有自动并行执行它们。\n",
    "* 设计包含更加复杂的数据依赖的计算任务，通过实验观察 MXNet 能否得到正确结果并提升计算性能。\n",
    "* 当运算符的计算量足够小时，仅在 CPU 或单 GPU 上并行计算也可能提升计算性能。设计实验来验证这一点。\n",
    "\n",
    "\n",
    "## 扫码直达[讨论区](https://discuss.gluon.ai/t/topic/1883)\n",
    "\n",
    "![](../img/qr_auto-parallelism.svg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
